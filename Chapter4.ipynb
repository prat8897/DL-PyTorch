{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rEUfyCpPTqQX"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOluJt6scV+qdj7v0pwCXbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prat8897/DL_PyTorch/blob/master/Chapter4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEUfyCpPTqQX",
        "colab_type": "text"
      },
      "source": [
        "## Real-world data representation using tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qgdfqr5TvXv",
        "colab_type": "text"
      },
      "source": [
        "This chapter covers\n",
        "- Representing real-world data as PyTorch tensors\n",
        "- Working with a range of data types\n",
        "- Loading data from a file\n",
        "- Converting data to tensors\n",
        "- Shaping tensors so they can be used as inputs for neural network models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKw_NFiQR4WY",
        "colab_type": "text"
      },
      "source": [
        "## Continuous, ordinal, and categorical values\n",
        "\n",
        "We should be aware of three different kinds of numerical values as we attempt to make sense of our data. The first kind is `continuous` values. These are the most intuitive when represented as numbers. They are strictly ordered, and a difference between various values has a strict meaning. Stating that package `A` is 2 kilograms heavier than package `B`, or that package `B` came from 100 miles farther away than `A` has a fixed meaning, regardless of whether package `A` is 3 kilograms or 10, or if `B` came from 200 miles away or 2,000. If you’re counting or measuring something with units, it’s probably a `continuous` value.\n",
        "The literature actually divides continuous values further: in the previous examples, it makes sense to say something is twice as heavy or three times farther away, so those values are said to be on a ratio scale. The time of day, on the other hand, does have the notion of difference, but it is not reasonable to claim that 6:00 is twice as late as 3:00; so time of day only offers aninterval scale.\n",
        "\n",
        "\n",
        "Next we have `ordinal` values. The strict ordering we have with continuous values remains, but the fixed relationship between values no longer applies. A good example of this is ordering a small, medium, or large drink, with small mapped to the value 1, medium 2, and large 3. The large drink is bigger than the medium, in the same way that 3 is bigger than 2, but it doesn’t tell us anything about how much bigger. If we were to convert our 1, 2, and 3 to the actual volumes (say, 8, 12, and 24 fluid ounces), then they would switch to being interval values. It’s important to remember that we can’t “do math” on the values outside of ordering them; trying to average large = 3 and small = 1 does not result in a medium drink!\n",
        "\n",
        "\n",
        "Finally, `categorical` values have neither ordering nor numerical meaning to their values. These are often just enumerations of possibilities assigned arbitrary numbers. Assigning water to 1, coffee to 2, soda to 3, and milk to 4 is a good example. There’s no real logic to placing water first and milk last; they simply need distinct values to differentiate them. We could assign coffee to 10 and milk to –3, and there would be no significant change (though assigning values in the range `0..N – 1` will have advantages for one-hot encoding and the embeddings we’ll discuss later). Because the numerical values bear no meaning, they are said to be on a `nominal` scale.\n",
        "\n",
        "\n",
        "|             | There is order between values | Distance between values have meaning |\n",
        "|-------------|-------------------------------|--------------------------------------|\n",
        "| `Continuous`  | Yes                           | Yes                                  |\n",
        "| `Ordinal`     | Yes                           | No                                   |\n",
        "| `Caterogical` | No                            | No                                   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY3ExcQUUhDv",
        "colab_type": "text"
      },
      "source": [
        "## Working with images\n",
        "\n",
        "### Loading an image file\n",
        "\n",
        "Images come in several different file formats, but luckily there are plenty of ways to load images in Python. Let’s start by loading a PNG image using the imageio module ([code/p1ch4/1_image_dog.ipynb](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch4/1_image_dog.ipynb)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpcxfaAtXU3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, threshold=50)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxI04mP5T5uK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69d9bee7-898e-44e4-fea2-36ecea0a8d18"
      },
      "source": [
        "import imageio\n",
        "img_arr = imageio.imread('/content/bobby.jpg')\n",
        "img_arr.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(720, 1280, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy7J9qZVXpTy",
        "colab_type": "text"
      },
      "source": [
        "At this point, img is a NumPy array-like object with three dimensions: two spatial dimensions, width and height; and a third dimension corresponding to the `red`, `green`, and `blue` channels. Any library that outputs a NumPy array will suffice to obtain a PyTorch tensor. The only thing to watch out for is the layout of the dimensions. PyTorch modules dealing with image data require tensors to be laid out as C × H × W : `channels`, `height`, and `width`, respectively.\n",
        "\n",
        "We can use the tensor’s `permute` method with the old dimensions for each new dimension to get to an appropriate layout. Given an input tensor H × W × C as obtained previously, we get a proper layout by having channel 2 first and then channels 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSxLQ4xLXQgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "05386265-c362-4dff-857c-e2b41c7d2723"
      },
      "source": [
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2, 0, 1) #HxWxC -> CxHxW\n",
        "out, out.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 77,  77,  ..., 117, 116],\n",
              "          [ 75,  76,  ..., 117, 116],\n",
              "          ...,\n",
              "          [215, 216,  ..., 174, 174],\n",
              "          [215, 216,  ..., 158, 158]],\n",
              " \n",
              "         [[ 45,  45,  ...,  77,  76],\n",
              "          [ 43,  44,  ...,  77,  76],\n",
              "          ...,\n",
              "          [165, 166,  ..., 124, 124],\n",
              "          [165, 166,  ..., 107, 107]],\n",
              " \n",
              "         [[ 22,  22,  ...,  51,  51],\n",
              "          [ 20,  21,  ...,  51,  50],\n",
              "          ...,\n",
              "          [ 78,  79,  ...,  55,  55],\n",
              "          [ 78,  79,  ...,  41,  41]]], dtype=torch.uint8),\n",
              " torch.Size([3, 720, 1280]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnJ2-7-uYuW6",
        "colab_type": "text"
      },
      "source": [
        "As a slightly more efficient alternative to using stack to build up the tensor, we can pre-allocate a tensor of appropriate size and fill it with images loaded from a directory, like so:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABce6cEWX3ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0ZbHv35Yzz2",
        "colab_type": "text"
      },
      "source": [
        "This indicates that our batch will consist of three RGB images 256 pixels in height and 256 pixels in width. Notice the type of the tensor: we’re expecting each color to be represented as an 8-bit integer, as in most photographic formats from standard consumer cameras. We can now load all PNG images from an input directory and store them in the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7miwfjUYxuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "data_dir = '/content/image-cats/'\n",
        "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
        "\n",
        "for i, filename in enumerate(filenames):\n",
        "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        "  img_t = torch.from_numpy(img_arr)\n",
        "  img_t = img_t.permute(2, 0, 1) #H × W × C\n",
        "  img_t = img_t[:3] #only keep first 3 channels\n",
        "  batch[i] = img_t"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcfNYS3BF99M",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the data\n",
        "\n",
        "We mentioned earlier that neural networks usually work with floating-point tensors as their input. Neural networks exhibit the best training performance when the input data ranges roughly from `0` to `1`, or from `-1` to `1` (this is an effect of how their building blocks are defined).\n",
        "\n",
        "\n",
        "So a typical thing we’ll want to do is cast a tensor to floating-point and normalize the values of the pixels. Casting to floating-point is easy, but normalization is trickier, as it depends on what range of the input we decide should lie between `0` and `1` (or `-1` and `1`). One possibility is to just divide the values of the pixels by `255` (the maximum representable number in 8-bit unsigned):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApBA44IHaJGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "743d931b-dbf3-4d92-efa0-8e48848cf75b"
      },
      "source": [
        "print(batch)\n",
        "batch = batch.float()\n",
        "batch /= 255.0  #normalize between 0 and 1\n",
        "print(batch)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[238, 238,  ..., 215, 215],\n",
            "          [238, 238,  ..., 215, 215],\n",
            "          ...,\n",
            "          [214, 213,  ..., 190, 192],\n",
            "          [214, 213,  ..., 190, 192]],\n",
            "\n",
            "         [[195, 195,  ..., 175, 175],\n",
            "          [195, 195,  ..., 175, 175],\n",
            "          ...,\n",
            "          [128, 127,  ..., 103, 105],\n",
            "          [128, 127,  ..., 103, 105]],\n",
            "\n",
            "         [[137, 137,  ..., 126, 126],\n",
            "          [137, 137,  ..., 126, 126],\n",
            "          ...,\n",
            "          [ 79,  78,  ...,  69,  71],\n",
            "          [ 79,  78,  ...,  69,  72]]],\n",
            "\n",
            "\n",
            "        [[[156, 152,  ..., 149, 158],\n",
            "          [174, 134,  ..., 136, 138],\n",
            "          ...,\n",
            "          [129, 130,  ..., 121, 114],\n",
            "          [129, 123,  ..., 121, 120]],\n",
            "\n",
            "         [[139, 135,  ..., 135, 147],\n",
            "          [160, 119,  ..., 122, 124],\n",
            "          ...,\n",
            "          [111, 111,  ..., 112, 105],\n",
            "          [111, 104,  ..., 110, 111]],\n",
            "\n",
            "         [[129, 123,  ..., 132, 145],\n",
            "          [155, 110,  ..., 119, 121],\n",
            "          ...,\n",
            "          [108, 108,  ..., 117, 110],\n",
            "          [107,  98,  ..., 115, 116]]],\n",
            "\n",
            "\n",
            "        [[[202, 193,  ...,  13,  12],\n",
            "          [199, 192,  ...,  14,  14],\n",
            "          ...,\n",
            "          [ 75,  68,  ...,  36,  37],\n",
            "          [ 85, 103,  ...,  37,  38]],\n",
            "\n",
            "         [[151, 139,  ...,   9,   8],\n",
            "          [151, 140,  ...,  11,  11],\n",
            "          ...,\n",
            "          [ 33,  26,  ...,  26,  27],\n",
            "          [ 40,  58,  ...,  27,  28]],\n",
            "\n",
            "         [[ 68,  53,  ...,   6,   5],\n",
            "          [ 67,  54,  ...,   6,   6],\n",
            "          ...,\n",
            "          [ 11,   2,  ...,  17,  18],\n",
            "          [ 19,  37,  ...,  18,  19]]]], dtype=torch.uint8)\n",
            "tensor([[[[0.9333, 0.9333,  ..., 0.8431, 0.8431],\n",
            "          [0.9333, 0.9333,  ..., 0.8431, 0.8431],\n",
            "          ...,\n",
            "          [0.8392, 0.8353,  ..., 0.7451, 0.7529],\n",
            "          [0.8392, 0.8353,  ..., 0.7451, 0.7529]],\n",
            "\n",
            "         [[0.7647, 0.7647,  ..., 0.6863, 0.6863],\n",
            "          [0.7647, 0.7647,  ..., 0.6863, 0.6863],\n",
            "          ...,\n",
            "          [0.5020, 0.4980,  ..., 0.4039, 0.4118],\n",
            "          [0.5020, 0.4980,  ..., 0.4039, 0.4118]],\n",
            "\n",
            "         [[0.5373, 0.5373,  ..., 0.4941, 0.4941],\n",
            "          [0.5373, 0.5373,  ..., 0.4941, 0.4941],\n",
            "          ...,\n",
            "          [0.3098, 0.3059,  ..., 0.2706, 0.2784],\n",
            "          [0.3098, 0.3059,  ..., 0.2706, 0.2824]]],\n",
            "\n",
            "\n",
            "        [[[0.6118, 0.5961,  ..., 0.5843, 0.6196],\n",
            "          [0.6824, 0.5255,  ..., 0.5333, 0.5412],\n",
            "          ...,\n",
            "          [0.5059, 0.5098,  ..., 0.4745, 0.4471],\n",
            "          [0.5059, 0.4824,  ..., 0.4745, 0.4706]],\n",
            "\n",
            "         [[0.5451, 0.5294,  ..., 0.5294, 0.5765],\n",
            "          [0.6275, 0.4667,  ..., 0.4784, 0.4863],\n",
            "          ...,\n",
            "          [0.4353, 0.4353,  ..., 0.4392, 0.4118],\n",
            "          [0.4353, 0.4078,  ..., 0.4314, 0.4353]],\n",
            "\n",
            "         [[0.5059, 0.4824,  ..., 0.5176, 0.5686],\n",
            "          [0.6078, 0.4314,  ..., 0.4667, 0.4745],\n",
            "          ...,\n",
            "          [0.4235, 0.4235,  ..., 0.4588, 0.4314],\n",
            "          [0.4196, 0.3843,  ..., 0.4510, 0.4549]]],\n",
            "\n",
            "\n",
            "        [[[0.7922, 0.7569,  ..., 0.0510, 0.0471],\n",
            "          [0.7804, 0.7529,  ..., 0.0549, 0.0549],\n",
            "          ...,\n",
            "          [0.2941, 0.2667,  ..., 0.1412, 0.1451],\n",
            "          [0.3333, 0.4039,  ..., 0.1451, 0.1490]],\n",
            "\n",
            "         [[0.5922, 0.5451,  ..., 0.0353, 0.0314],\n",
            "          [0.5922, 0.5490,  ..., 0.0431, 0.0431],\n",
            "          ...,\n",
            "          [0.1294, 0.1020,  ..., 0.1020, 0.1059],\n",
            "          [0.1569, 0.2275,  ..., 0.1059, 0.1098]],\n",
            "\n",
            "         [[0.2667, 0.2078,  ..., 0.0235, 0.0196],\n",
            "          [0.2627, 0.2118,  ..., 0.0235, 0.0235],\n",
            "          ...,\n",
            "          [0.0431, 0.0078,  ..., 0.0667, 0.0706],\n",
            "          [0.0745, 0.1451,  ..., 0.0706, 0.0745]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3RBqicVGwPT",
        "colab_type": "text"
      },
      "source": [
        "Another possibility is to compute the *mean* and *standard deviation* of the input data and scale it so that the output has *zero* mean and unit standard deviation across each channel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVi2G5GyGr7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "c2fc0f43-8abb-48c5-bc68-35d9e44573b4"
      },
      "source": [
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        "  mean = torch.mean(batch[:, c])\n",
        "  std = torch.std(batch[:, c])\n",
        "  batch[:, c] = (batch[:, c] - mean) / std\n",
        "\n",
        "print(batch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 1.5978,  1.5978,  ...,  1.1900,  1.1900],\n",
            "          [ 1.5978,  1.5978,  ...,  1.1900,  1.1900],\n",
            "          ...,\n",
            "          [ 1.1723,  1.1545,  ...,  0.7467,  0.7822],\n",
            "          [ 1.1723,  1.1545,  ...,  0.7467,  0.7822]],\n",
            "\n",
            "         [[ 1.5253,  1.5253,  ...,  1.1460,  1.1460],\n",
            "          [ 1.5253,  1.5253,  ...,  1.1460,  1.1460],\n",
            "          ...,\n",
            "          [ 0.2546,  0.2356,  ..., -0.2196, -0.1816],\n",
            "          [ 0.2546,  0.2356,  ..., -0.2196, -0.1816]],\n",
            "\n",
            "         [[ 0.9416,  0.9416,  ...,  0.7182,  0.7182],\n",
            "          [ 0.9416,  0.9416,  ...,  0.7182,  0.7182],\n",
            "          ...,\n",
            "          [-0.2364, -0.2567,  ..., -0.4395, -0.3989],\n",
            "          [-0.2364, -0.2567,  ..., -0.4395, -0.3785]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1439,  0.0730,  ...,  0.0198,  0.1794],\n",
            "          [ 0.4631, -0.2461,  ..., -0.2107, -0.1752],\n",
            "          ...,\n",
            "          [-0.3348, -0.3171,  ..., -0.4766, -0.6007],\n",
            "          [-0.3348, -0.4412,  ..., -0.4766, -0.4944]],\n",
            "\n",
            "         [[ 0.4632,  0.3874,  ...,  0.3874,  0.6149],\n",
            "          [ 0.8615,  0.0839,  ...,  0.1408,  0.1787],\n",
            "          ...,\n",
            "          [-0.0678, -0.0678,  ..., -0.0489, -0.1816],\n",
            "          [-0.0678, -0.2006,  ..., -0.0868, -0.0678]],\n",
            "\n",
            "         [[ 0.7792,  0.6573,  ...,  0.8401,  1.1041],\n",
            "          [ 1.3072,  0.3933,  ...,  0.5761,  0.6167],\n",
            "          ...,\n",
            "          [ 0.3526,  0.3526,  ...,  0.5354,  0.3933],\n",
            "          [ 0.3323,  0.1495,  ...,  0.4948,  0.5151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9595,  0.7999,  ..., -2.3915, -2.4092],\n",
            "          [ 0.9063,  0.7822,  ..., -2.3738, -2.3738],\n",
            "          ...,\n",
            "          [-1.2922, -1.4163,  ..., -1.9837, -1.9660],\n",
            "          [-1.1149, -0.7958,  ..., -1.9660, -1.9482]],\n",
            "\n",
            "         [[ 0.6908,  0.4632,  ..., -2.0024, -2.0214],\n",
            "          [ 0.6908,  0.4822,  ..., -1.9645, -1.9645],\n",
            "          ...,\n",
            "          [-1.5472, -1.6800,  ..., -1.6800, -1.6610],\n",
            "          [-1.4144, -1.0731,  ..., -1.6610, -1.6420]],\n",
            "\n",
            "         [[-0.4598, -0.7644,  ..., -1.7190, -1.7394],\n",
            "          [-0.4801, -0.7441,  ..., -1.7190, -1.7190],\n",
            "          ...,\n",
            "          [-1.6175, -1.8003,  ..., -1.4956, -1.4753],\n",
            "          [-1.4550, -1.0894,  ..., -1.4753, -1.4550]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKRJJezCJj_q",
        "colab_type": "text"
      },
      "source": [
        "Here, we normalize just a single batch of images because we do not know yet how to operate on an entire dataset. In working with images, it is good practice to compute the *mean* and *standard deviation* on all the training data in advance and then subtract and divide by these fixed, precomputed quantities.\n",
        "\n",
        "We can perform several other operations on inputs, such as geometric transforma- tions like rotations, scaling, and cropping. These may help with training or may be required to make an arbitrary input conform to the input requirements of a network, like the size of the image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4RzAtUpJufu",
        "colab_type": "text"
      },
      "source": [
        "## 3D images: Volumetric data\n",
        "\n",
        "### Loading a specialized format\n",
        "\n",
        "Let’s load a sample CT scan using the `volread` function in the `imageio` module, which takes a directory as an argument and assembles all Digital Imaging and Communications in Medicine (DICOM) files2 in a series in a NumPy 3D array [(code/p1ch4/ 2_volumetric_ct.ipynb)](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch4/2_volumetric_ct.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t-rsJmWKcDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6282640f-74b4-4fe0-e684-c8bf7719b84b"
      },
      "source": [
        "import imageio\n",
        "dir_path = \"/content/2-LUNG 3.0  B70f-04083\"\n",
        "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
        "vol_arr.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading DICOM (examining files): 1/99 files (1.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b99/99 files (100.0%)\n",
            "  Found 1 correct series.\n",
            "Reading DICOM (loading data): 29/99  (29.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b99/99  (100.0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzF21AxFMjC8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The layout is different from what PyTorch expects, due to having no channel information. So we’ll have to make room for the channel dimension using `unsqueeze`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6kXezbPMLFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff2be75e-059b-4295-8583-1c499ea8b9d5"
      },
      "source": [
        "vol = torch.from_numpy(vol_arr).float()\n",
        "vol = torch.unsqueeze(vol, 0)\n",
        "vol.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 99, 512, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yfv5w3GMwb7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "At this point we could assemble a 5D dataset by stacking multiple volumes along the `batch` direction, just as we did in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Y15w4WNL2L",
        "colab_type": "text"
      },
      "source": [
        "## Representing tabular data\n",
        "\n",
        "The simplest form of data we’ll encounter on a machine learning job is sitting in a spreadsheet, CSV file, or database. Whatever the medium, it’s a table containing one row per sample (or record), where columns contain one piece of information about our sample.\n",
        "\n",
        "At first we are going to assume there’s no meaning to the order in which samples appear in the table: such a table is a collection of independent samples, unlike a time series, for instance, in which samples are related by a time dimension.\n",
        "\n",
        "Columns may contain numerical values, like temperatures at specific locations; or labels, like a string expressing an attribute of the sample, like “blue.” Therefore, tabular data is typically not homogeneous: different columns don’t have the same type. We might have a column showing the weight of apples and another encoding their color in a label.\n",
        "PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is typically encoded as a number, typically `floating-point` (though `integer` types and `Boolean` are supported as well). This numeric encoding is deliberate, since neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7yIVp3NNj_E",
        "colab_type": "text"
      },
      "source": [
        "### Using a real-world dataset\n",
        "\n",
        "Our first job as deep learning practitioners is to encode heterogeneous, real-world data into a tensor of floating-point numbers, ready for consumption by a neural network. A large number of tabular datasets are freely available on the internet; see, for instance, https://github.com/caesar0301/awesome-public-datasets.\n",
        "\n",
        "Let’s start with something fun: wine! The Wine Quality dataset is a freely available table containing chemical characterizations of samples of vinho verde, a wine from north Portugal, together with a sensory quality score. The dataset for white wines can be downloaded here: http://mng.bz/90Ol. For convenience, we also created a copy of the dataset on the Deep Learning with PyTorch Git repository, under data/p1ch4/tabular-wine.\n",
        "\n",
        "\n",
        "The file contains a comma-separated collection of values organized in 12 columns preceded by a header line containing the column names. The first 11 columns contain values of chemical variables, and the last column contains the sensory quality score from 0 (very bad) to 10 (excellent). These are the column names in the order they appear in the dataset:\n",
        "\n",
        "  - fixed acidity\n",
        "  - volatile acidity\n",
        "  - citric acid\n",
        "  - residual sugar\n",
        "  - chlorides\n",
        "  - free sulfur dioxide\n",
        "  - total sulfur dioxide\n",
        "  - density\n",
        "  - pH\n",
        "  - sulphates\n",
        "  - alcohol\n",
        "  - quality\n",
        "  \n",
        "\n",
        "A possible machine learning task on this dataset is predicting the quality score from chemical characterization alone. We’re hoping to find a relationship between one of the chemical columns in our data and the quality column. Here, we’re expecting to see quality increase as sulfur decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIF9RBW-OfOa",
        "colab_type": "text"
      },
      "source": [
        "### Loading a wine data tensor\n",
        "\n",
        "We need to be able to examine the data in a more usable way than opening the file in a text editor. Let’s see how we can load the data using Python and then turn it into a PyTorch tensor. Python offers several options for quickly loading a CSV file. Three popular options are\n",
        "\n",
        "\n",
        "- The csv module that ships with Python\n",
        "- NumPy\n",
        "- Pandas\n",
        "\n",
        "Let's use NumPy for this example. We can load our file and turn the resulting NumPy array into a PyTorch tensor [(code/p1ch4/3_tabular_wine.ipynb)](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch4/3_tabular_wine.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REHFDco6Mpmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7a7c340d-5656-48f6-8439-9b4a27af2578"
      },
      "source": [
        "import csv\n",
        "wine_path = \"/content/winequality-white.csv\"\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",skiprows=1)\n",
        "wineq_numpy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZVsaaHcPVuV",
        "colab_type": "text"
      },
      "source": [
        "Here we just prescribe what the type of the 2D array should be (`32-bit floating-point`), the `delimiter` used to separate values in each row, and the fact that the first line should not be read since it contains the column names. Let’s check that all the data has been read:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlSQku8wPPzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e8215e8d-cbeb-4b54-ac3b-fda979b612ec"
      },
      "source": [
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "wineq_numpy.shape, col_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4898, 12),\n",
              " ['fixed acidity',\n",
              "  'volatile acidity',\n",
              "  'citric acid',\n",
              "  'residual sugar',\n",
              "  'chlorides',\n",
              "  'free sulfur dioxide',\n",
              "  'total sulfur dioxide',\n",
              "  'density',\n",
              "  'pH',\n",
              "  'sulphates',\n",
              "  'alcohol',\n",
              "  'quality'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Psn3XVVPm9Y",
        "colab_type": "text"
      },
      "source": [
        "and proceed to convert the `NumPy` array to a `PyTorch` tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZdtZDY3Pd0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efe7f50a-bba7-4542-a927-f08b67bb0384"
      },
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.dtype"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sliz55IIPwyo",
        "colab_type": "text"
      },
      "source": [
        "At this point, we have a floating-point `torch.Tensor` containing all the columns, including the last, which refers to the `quality` score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrXuscm5Q29v",
        "colab_type": "text"
      },
      "source": [
        "### Representing scores\n",
        "\n",
        "We could treat the score as a `continuous` variable, keep it as a real number, and perform a regression task, or treat it as a `label` and try to guess the `label` from the chemical analysis in a classification task. In both approaches, we will typically remove the score from the tensor of input data and keep it in a separate tensor, so that we can use the score as the ground truth without it being input to our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7L36ssAPsmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6a3ba5f4-2982-4c98-9089-b10a04834217"
      },
      "source": [
        "data = wineq[:, :-1] #Select all rows and all columns except the last\n",
        "data, data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  ...,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  ...,  0.4900,  9.5000],\n",
              "         ...,\n",
              "         [ 5.5000,  0.2900,  ...,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  ...,  0.3200, 11.8000]]), torch.Size([4898, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfmdQ6ccScC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44028e24-17aa-49c3-a898-ec3d742d965c"
      },
      "source": [
        "target = wineq[:, -1] #Select all rows and the last columns\n",
        "target, target.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6.,  ..., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLB4PHp8S56d",
        "colab_type": "text"
      },
      "source": [
        "If we want to transform the `target` tensor in a tensor of labels, we have two options, depending on the strategy or what we use the categorical data for. One is simply to treat labels as an integer vector of scores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejn1tK0wSwyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "180a70f0-4a18-41a0-ca7a-6e39c69d4840"
      },
      "source": [
        "target = wineq[:, -1].long()\n",
        "target"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6,  ..., 7, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDJmU9wYUWH8",
        "colab_type": "text"
      },
      "source": [
        "If targets were string labels, like wine color, assigning an integer number to each string would let us follow the same approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCVs0KQjUXuD",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "The other approach is to build a one-hot encoding of the scores: that is, encode each of the 10 scores in a vector of 10 elements, with all elements set to 0 but one, at a different index for each score. This way, a score of `1` could be mapped onto the vector `(1,0,0,0,0,0,0,0,0,0)`, a score of `5` onto `(0,0,0,0,1,0,0,0,0,0)`, and so on. Note that the fact that the score corresponds to the index of the nonzero element is purely incidental: we could shuffle the assignment, and nothing would change from a classification standpoint.\n",
        "\n",
        "Keeping wine quality scores in an integer vector of scores induces an ordering on the scores—which might be totally appropriate in this case, since a score of 1 is lower than a score of 4. It also induces some sort of distance between scores: that is, the distance between 1 and 3 is the same as the distance between 2 and 4. If this holds for our quantity, then great. If, on the other hand, scores are purely discrete, like grape variety, one-hot encoding will be a much better fit, as there’s no implied ordering or distance. One-hot encoding is also appropriate for quantitative scores when fractional values in between integer scores, like `2.4`, make no sense for the application—for when the score is either *this* or that.\n",
        "\n",
        "We can achieve one-hot encoding using the `scatter_` method, which fills the tensor with values from a source tensor along the indices provided as arguments:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyVeLBQYT8GT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2fbb07eb-bd15-4156-f254-a4e29e6705eb"
      },
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiG0JCqDPXnk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let’s see what `scatter_` does. First, we notice that its name ends with an underscore. As you learned in the previous chapter, this is a convention in PyTorch that indicates the method will not return a new tensor, but will instead modify the tensor in place. The arguments for `scatter_` are as follows:\n",
        "\n",
        "- The dimension along which the following two arguments are specified\n",
        "- A column tensor indicating the indices of the elements to scatter\n",
        "- A tensor containing the elements to scatter or a single scalar to scatter (`1.0`, in this case)\n",
        "\n",
        "In other words, the previous invocation reads, “For each row, take the index of the target label (which coincides with the score in our case) and use it as the column index to set the value `1.0`.” The end result is a tensor encoding categorical information.\n",
        "\n",
        "The second argument of `scatter_`, the `index` tensor, is required to have the same number of dimensions as the tensor we scatter into. Since `target_onehot` has two dimensions `(4,898 × 10)`, we need to add an extra dummy dimension to target using `unsqueeze`:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYrZdCHNVR-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ff850873-5d6f-478c-b67b-7596c6a384bd"
      },
      "source": [
        "target_unsqueezed = target.unsqueeze(1)\n",
        "target_unsqueezed"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [6],\n",
              "        ...,\n",
              "        [7],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2Zx3O_dP0kc",
        "colab_type": "text"
      },
      "source": [
        "The call to `unsqueeze` adds a singleton dimension, from a `1D` tensor of `4,898` elements to a `2D` tensor of size `(4,898 × 1)`, without changing its contents—no extra elements are added; we just decided to use an extra index to access the elements. That is, we access the first element of target as `target[0]` and the first element of its unsqueezed counterpart as `target_unsqueezed[0,0]`.\n",
        "\n",
        "\n",
        "PyTorch allows us to use class indices directly as targets while training neural networks. However, if we wanted to use the score as a categorical input to the network, we would have to transform it to a one-hot-encoded tensor.\n",
        "\n",
        "\n",
        "Let’s go back to our `data` tensor, containing the 11 variables associated with the chemical analysis. We can use the functions in the PyTorch Tensor API to manipulate our data in tensor form. Let’s first obtain the *mean* and *standard deviations* for each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw-Nbp1rSLuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f2d2f496-5f7f-4069-eddb-40118af2b5ec"
      },
      "source": [
        "print(data)\n",
        "data_mean = torch.mean(data, dim=0)\n",
        "data_mean"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 7.0000,  0.2700,  ...,  0.4500,  8.8000],\n",
            "        [ 6.3000,  0.3000,  ...,  0.4900,  9.5000],\n",
            "        ...,\n",
            "        [ 5.5000,  0.2900,  ...,  0.3800, 12.8000],\n",
            "        [ 6.0000,  0.2100,  ...,  0.3200, 11.8000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
              "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRuAFkN_SQxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40bb181f-2c61-49bc-f872-d6f404e281cb"
      },
      "source": [
        "data_var = torch.var(data, dim=0)\n",
        "data_var"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
              "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1OKncqQSVGJ",
        "colab_type": "text"
      },
      "source": [
        "In this case, `dim=0` indicates that the reduction is performed along dimension `0`. At this point, we can normalize the data by subtracting the *mean* and dividing by the *standard deviation*, which helps with the learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXiAo4E4SdPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "36f1c38a-275f-4fcd-9846-f2a842cce37c"
      },
      "source": [
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "data_normalized"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.7209e-01, -8.1764e-02,  ..., -3.4914e-01, -1.3930e+00],\n",
              "        [-6.5743e-01,  2.1587e-01,  ...,  1.3467e-03, -8.2418e-01],\n",
              "        ...,\n",
              "        [-1.6054e+00,  1.1666e-01,  ..., -9.6250e-01,  1.8574e+00],\n",
              "        [-1.0129e+00, -6.7703e-01,  ..., -1.4882e+00,  1.0448e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrWjvQTfP-9f",
        "colab_type": "text"
      },
      "source": [
        "### When to categorize\n",
        "\n",
        "We have seen ways to deal with both *continuous* and *categorical* data. You may wonder what the deal is with the *ordinal* case discussed in the earlier sidebar. There is no general recipe for it; most commonly, such data is either treated as *categorical* (losing the ordering part, and hoping that maybe our model will pick it up during training if we only have a few categories) or *continuous* (introducing an arbitrary notion of distance)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF-v8Ww_TQgT",
        "colab_type": "text"
      },
      "source": [
        "### Finding Thresholds\n",
        "\n",
        "Next, let’s start to look at the data with an eye to seeing if there is an easy way to tell good and bad wines apart at a glance. First, we’re going to determine which rows in target correspond to a score less than or equal to 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HduVeJ-7TZr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "36425ce5-94a7-4061-b698-cfe0cb8daa2e"
      },
      "source": [
        "print(target)\n",
        "bad_indexes = target <= 3\n",
        "print(bad_indexes)\n",
        "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6, 6,  ..., 7, 6])\n",
            "tensor([False, False,  ..., False, False])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Z5PjXVToAW",
        "colab_type": "text"
      },
      "source": [
        "Note that only `20` of the `bad_indexes` entries are set to True! By using a feature in PyTorch called *advanced indexing*, we can use a tensor with data type `torch.bool` to index the data tensor. This will essentially filter data to be only items (or rows) corresponding to `True` in the indexing tensor. The `bad_indexes` tensor has the same `shape` as target, with values of `False` or `True` depending on the outcome of the comparison between our threshold and each element in the original target tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV13i2D6Tgb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "98db833a-e5f7-446c-a3b0-37e3b5ddd4e2"
      },
      "source": [
        "print(data, bad_indexes)\n",
        "bad_data = data[bad_indexes] #!?!\n",
        "bad_data, bad_data.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 7.0000,  0.2700,  ...,  0.4500,  8.8000],\n",
            "        [ 6.3000,  0.3000,  ...,  0.4900,  9.5000],\n",
            "        ...,\n",
            "        [ 5.5000,  0.2900,  ...,  0.3800, 12.8000],\n",
            "        [ 6.0000,  0.2100,  ...,  0.3200, 11.8000]]) tensor([False, False,  ..., False, False])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 8.5000,  0.2600,  ...,  0.5000,  9.8000],\n",
              "         [ 5.8000,  0.2400,  ...,  0.4300, 11.7000],\n",
              "         ...,\n",
              "         [ 6.8000,  0.2600,  ...,  0.5200, 10.5000],\n",
              "         [ 6.1000,  0.2600,  ...,  0.6400, 10.5000]]), torch.Size([20, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mPLHrZNV3N0",
        "colab_type": "text"
      },
      "source": [
        "Note that the new `bad_data` tensor has `20` rows, the same as the number of rows with `True` in the `bad_indexes` tensor. It retains all 11 columns. Now we can start to get information about wines grouped into good, middling, and bad categories. Let’s take the `.mean()` of each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36zri7W-Va2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_data = data[target <= 3]\n",
        "mid_data = data[(target > 3) & (target < 7)] #note the '&' instead of 'and'\n",
        "good_data = data[target >= 7]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ0a1ysAZ6r9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6243a90c-981a-4d52-f022-2b2c853a8a91"
      },
      "source": [
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "\n",
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        "  print('{:2} {:20} {:7.2f} {:7.2f} {:7.2f}'.format(i, *args))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0 fixed acidity           7.60    6.89    6.73\n",
            " 1 volatile acidity        0.33    0.28    0.27\n",
            " 2 citric acid             0.34    0.34    0.33\n",
            " 3 residual sugar          6.39    6.71    5.26\n",
            " 4 chlorides               0.05    0.05    0.04\n",
            " 5 free sulfur dioxide    53.33   35.42   34.55\n",
            " 6 total sulfur dioxide  170.60  141.83  125.25\n",
            " 7 density                 0.99    0.99    0.99\n",
            " 8 pH                      3.19    3.18    3.22\n",
            " 9 sulphates               0.47    0.49    0.50\n",
            "10 alcohol                10.34   10.26   11.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIq3fcBDbPva",
        "colab_type": "text"
      },
      "source": [
        "It looks like we’re on to something here: at first glance, the bad wines seem to have higher total sulfur dioxide, among other differences. We could use a threshold on total sulfur dioxide as a crude criterion for discriminating good wines from bad ones. Let’s get the indexes where the total sulfur dioxide column is below the midpoint we calculated earlier, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBNFV8n-aFdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6a9e2ed-92ea-4c2f-fe84-598f16f54286"
      },
      "source": [
        "total_sulfur_threshold = 141.83\n",
        "total_sulfur_data = data[:,6] #select all rows and sixth column\n",
        "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
        "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(2727))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us6-7tETcF2a",
        "colab_type": "text"
      },
      "source": [
        "This means our threshold implies that just over half of all the wines are going to be high quality. Next, we’ll need to get the indexes of the actually good wines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcKQKhUJcCga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35097266-0d7c-4f17-ad46-8a57f16d1f91"
      },
      "source": [
        "actual_indexes = target > 5\n",
        "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(3258))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB058-VNcjVY",
        "colab_type": "text"
      },
      "source": [
        "Since there are about 500 more actually good wines than our threshold predicted, we already have hard evidence that it’s not perfect. Now we need to see how well our predictions line up with the actual rankings. We will perform a logical “`and`” between our prediction indexes and the actual good indexes (remember that each is just an array of zeros and ones) and use that intersection of wines-in-agreement to determine how well we did:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52snZbqTcMWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8c7ad74-bd65-4ae8-8c52-49298d00adb6"
      },
      "source": [
        "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
        "n_predicted = torch.sum(predicted_indexes).item()\n",
        "n_actual = torch.sum(actual_indexes).item()\n",
        "n_matches, n_matches / n_predicted, n_matches / n_actual"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2018, 0.74000733406674, 0.6193984039287906)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwu0ALqmfTXE",
        "colab_type": "text"
      },
      "source": [
        "We got around `2,000` wines right! Since we predicted `2,700` wines, this gives us a `74%` chance that if we predict a wine to be high quality, it actually is. Unfortunately, there are `3,200` good wines, and we only identified `61% `of them. Well, we got what we signed up for; that’s barely better than random!\n",
        "\n",
        "Of course, this is all very naive: we know for sure that multiple variables contribute to wine quality, and the relationships between the values of these variables and the outcome (which could be the actual score, rather than a binarized version of it) is likely more complicated than a simple threshold on a single value.\n",
        "\n",
        "\n",
        "Indeed, a simple neural network would overcome all of these limitations, as would a lot of other basic machine learning methods. We’ll have the tools to tackle this problem after the next two chapters, once we have learned how to build our first neural network from scratch. We will also revisit how to better grade our results in chapter 12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PypzDKhCfbj1",
        "colab_type": "text"
      },
      "source": [
        "## Working with time series\n",
        "\n",
        "Let's switch to another interesting dataset: data from a Washington, D.C., bike-sharing system reporting the hourly count of rental bikes in 2011–2012 in the Capital Bikeshare system, along with weather and seasonal information (available here: http://mng.bz/jgOx). Our goal will be to take a flat, 2D dataset and transform it into 3D.\n",
        "\n",
        "### Adding a time dimension\n",
        "\n",
        "In the source data, each row is a separate hour of data. We want to change the row-per-hour organization so that we have one axis that increases at a rate of one day per index increment, and another axis that represents the hour of the day (independent of the date). The third axis will be our different columns of data (weather, temperature, and so on).\n",
        "Let’s load the data [(code/p1ch4/4_time_series_bikes.ipynb)](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch4/4_time_series_bikes.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn_3NKiGfZ6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f917f07-581b-4d79-873b-8c62a629f515"
      },
      "source": [
        "bikes_numpy = np.loadtxt(\"/content/hour-fixed.csv\",\n",
        "                         dtype=np.float32,\n",
        "                         delimiter=\",\",\n",
        "                         skiprows=1,\n",
        "                         converters={1: lambda x: float(x[8:10])}) #Converts date strings to numbers corresponding to the day of the month in column 1\n",
        "bikes = torch.from_numpy(bikes_numpy)\n",
        "bikes"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 1.0000e+00,  ..., 1.3000e+01, 1.6000e+01],\n",
              "        [2.0000e+00, 1.0000e+00,  ..., 3.2000e+01, 4.0000e+01],\n",
              "        ...,\n",
              "        [1.7378e+04, 3.1000e+01,  ..., 4.8000e+01, 6.1000e+01],\n",
              "        [1.7379e+04, 3.1000e+01,  ..., 3.7000e+01, 4.9000e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt5G7i2vkLyj",
        "colab_type": "text"
      },
      "source": [
        "For every hour, the dataset reports the following variables:\n",
        "\n",
        "- Index of record: `instant`\n",
        "- Day of month: `day`\n",
        "- Season: `season` (`1`: spring, `2`: summer, `3`: fall, `4`: winter)\n",
        "- Year: `yr` (`0`: 2011, `1`: 2012)\n",
        "- Month:`mnth`(`1`to `12`)\n",
        "- Hour: `hr`(`0`to `23`)\n",
        "- Holiday status: `holiday`\n",
        "- Day of the week: `weekday`\n",
        "- Working day status: `workingday`\n",
        "- Weather situation: `weathersit` (`1`: clear, `2`:mist, `3`: light rain/snow, `4`: heavy\n",
        "rain/snow)\n",
        "- Temperature in °C: `temp`\n",
        "- Perceived temperature in °C: `atemp`\n",
        "- Humidity:`hum`\n",
        "- Wind speed: `windspeed`\n",
        "- Number of casual users: `casual`\n",
        "- Number of registered users: `registered`\n",
        "- Count of rental bikes: `cnt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9DsIwQUjatP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}